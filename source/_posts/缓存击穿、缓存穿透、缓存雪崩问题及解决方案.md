---
title: 缓存击穿、缓存穿透、缓存雪崩问题及解决方案
date: 2025-08-24
description: 这篇文章详细介绍了缓存系统中常见的三个问题及其解决方案：缓存击穿、缓存穿透和缓存雪崩。缓存击穿是指热点key失效导致大量请求直接访问数据库，可通过互斥锁、逻辑过期等方案解决；缓存穿透是指查询不存在的数据导致请求直接打到数据库，可通过参数校验、缓存空值和布隆过滤器等方式防范；缓存雪崩是指大量缓存key同时过期导致数据库压力骤增，可通过设置随机过期时间、缓存永不过期、缓存预热和多级缓存等策略应对。文章还提供了具体的代码示例和实现方案，帮助读者更好地理解和应用这些缓存优化技术。
tags:
  - Redis
  - MySQL
  - 缓存
categories:
  - Redis
---
# 缓存击穿

## 什么是缓存击穿？

缓存击穿指的是某个热点 key 在缓存中突然失效了，导致大量的请求都到达数据库，给数据库带来了不必要的压力。

## 缓存击穿的解决方案

- 互斥锁/分布式锁
- 逻辑过期
- 互斥锁/分布式锁 + 逻辑过期
- 定时刷新

### 互斥锁/分布式锁

互斥锁/分布式锁的具体原理就是：利用锁的互斥性，保证多个请求中只有一个请求能够到达数据库并访问数据库进行更新缓存，其它的请求阻塞等待。

需要做一个双重检测的机制，避免重复查询。其他请求拿到锁之后先判断缓存中是否存在数据，存在数据直接返回即可。

伪代码如下：

```java
String cacheKey = "hot_key";
Object cached = redis.get(cacheKey);

if (cached != null) {
    return cached; // 缓存命中, 直接返回
}

// 1. 尝试获取分布式锁(比如用 Redis 的 SETNX 或 RedLock)
String lockKey = "lock:" + cacheKey;
boolean locked = redis.setIfAbsent(lockKey, "1", 10, TimeUnit.SECONDS); // 设置 10 秒超时

if (locked) {
    try {
        // 2. 双重检查, 可能其他线程已经重建好缓存了
        cached = redis.get(cacheKey);
        if (cached != null) {
            return cached;
        }

        // 3. 查数据库
        Object dbData = queryFromDB(cacheKey);

        // 4. 写回缓存
        redis.set(cacheKey, dbData, 3600); // 设置新的过期时间

        return dbData;
    } finally {
        // 释放锁
        redis.del(lockKey);
    }
} else {
    // 没抢到锁, 短暂等待后重试, 或者直接返回旧数据/默认值
    Thread.sleep(100);
    return getFromCacheWithLock(cacheKey); // 重试, 或者 return 默认值/兜底数据
}
```

这种方式数据一致性比较强，但是需要阻塞等待，会对性能造成一定影响。

### 逻辑过期

逻辑过期就是指不设置缓存 key 的过期时间，使其永不过期，由我们在保存缓存数据的时候手动维护一个 `expireTime` 字段到 Redis 当中。比如保存 JSON 或 Map 的时候显式的指定一个 `expireTime` 字段，字段中保存当前时间的时间戳 + 手动的过期时间。

每次获取数据的时候，解析相应的 `expireTime` 字段，与当前的时间戳进行比较，若保存的时间戳大于当前时间，则表示还没有逻辑过期，否则就已经过期，过期之后可以开启一个新的线程更新缓存或者使用消息队列去更新缓存。

该方案可能会存在短暂时间的脏数据，但是不需要阻塞请求。

### 互斥锁/分布式锁 + 逻辑过期

实际环境中，都是二者一起去使用来防止缓存击穿的，伪代码如下：

```java
@Service
public class CacheService {

    @Autowired
    private StringRedisTemplate redisTemplate;

    // 逻辑过期时间: 例如 10 分钟
    private static final long LOGICAL_EXPIRE_TIME = 10 * 60 * 1000;

    // 缓存 key
    private static final String CACHE_KEY = "product:123";

    public String getDataWithLogicalExpire() {
        String jsonStr = redisTemplate.opsForValue().get(CACHE_KEY);

        // 1. 缓存为空, 需要重建
        if (jsonStr == null) {
            return rebuildCacheAndReturn();
        }

        // 2. 解析 JSON 获取 expireTime
        JSONObject jsonObject = JSON.parseObject(jsonStr);
        Long expireTime = jsonObject.getLong("expireTime");
        String data = jsonObject.getString("data");

        // 3. 判断是否逻辑过期
        if (expireTime > System.currentTimeMillis()) {
            // 未过期，直接返回数据
            return data;
        } else {
            // 已逻辑过期，触发异步缓存更新（防止击穿）
            asyncRefreshCache();
            // 依然返回旧数据（可容忍短暂脏读）
            return data;
        }
    }

    // 异步刷新缓存(可用线程池或消息队列)
    private void asyncRefreshCache() {
        // 提交到线程池执行, 避免阻塞主线程
        ThreadPool.submit(() -> {
            try {
                // 获取最新数据
                String freshData = queryFromDatabase();

                // 构造新的 JSON, 设置新的逻辑过期时间
                JSONObject newJson = new JSONObject();
                newJson.put("data", freshData);
                newJson.put("expireTime", System.currentTimeMillis() + LOGICAL_EXPIRE_TIME);

                // 更新 Redis 缓存
                redisTemplate.opsForValue().set(CACHE_KEY, newJson.toJSONString());
            } catch (Exception e) {
                // 记录日志, 避免影响主流程
                log.error("异步刷新缓存失败", e);
            }
        });
    }

    // 首次缓存为空时, 同步重建并返回
    private String rebuildCacheAndReturn() {
        // 加分布式锁, 防止缓存击穿(多个线程同时重建)
        Boolean locked = redisTemplate.opsForValue().setIfAbsent("lock:" + CACHE_KEY, "1", 10, TimeUnit.SECONDS);
        if (!locked) {
            // 未获取到锁, 短暂等待或直接查库(降级)
            Thread.sleep(100);
            return getDataWithLogicalExpire(); // 递归重试
        }

        try {
            // 查询数据库
            String freshData = queryFromDatabase();

            // 构建带逻辑过期的 JSON
            JSONObject newJson = new JSONObject();
            newJson.put("data", freshData);
            newJson.put("expireTime", System.currentTimeMillis() + LOGICAL_EXPIRE_TIME);

            // 写入 Redis
            redisTemplate.opsForValue().set(CACHE_KEY, newJson.toJSONString());

            return freshData;
        } finally {
            // 释放锁
            redisTemplate.delete("lock:" + CACHE_KEY);
        }
    }

    private String queryFromDatabase() {
        // 模拟查库
        return "Data from DB";
    }
}
```

### 定时刷新

使用定时任务框架，比如 Spring Scheduler、xxl-job 等，针对每个热点 key 进行记录过期时间，在过期时间之前刷新数据，比如 1 分种过期时间进行数据刷新。

# 缓存穿透

## 什么是缓存穿透？

缓存穿透指的是数据在缓存和数据库中都不存在，从而导致大量的请求直接访问数据库，造成数据库压力过载，甚至出现宕机。

## 缓存穿透解决方案

缓存穿透的解决可以分为多个步骤。

### 第一步

首先对请求参数做好校验，拦截非法的请求。对于一些异常的用户或者异常的 IP 直接进行限流或者设置黑名单禁止访问，可以在网关层中进行拦截。

### 第二步

对于数据库中查不到的数据缓存一个空值进行返回，同时设置一个较短的过期时间，避免后续增加了该数据后反而查不到。

### 第三步

如果恶意用户构造大量不存在的数据疯狂攻击我们，那么缓存空值就力不从心了，可以使用布隆过滤器来实现。写数据库的时候同时写布隆过滤器，后续打来的请求通过布隆过滤器进行判断。

布隆过滤器就是把数据经过多个 hash 函数进行计算得到多个 hash 值，然后把 hash 值映射到一个 bitmap 中，把对应位置修改为 1。请求来了，就对这些数据用 hash 函数做计算，然后看看这几个 hash 值对应的 bitmap 的那个位置上是不是 1，是 1 说明有，是 0 说明没有。

但是布隆过滤器是存在一定误判的可能的。且布隆过滤器不支持删除，因为无法确定哪个哈希值是哪个元素设置的。

# 缓存雪崩

## 什么是缓存雪崩？

缓存雪崩指的是在同一时期大量的缓存 key 突然 **同时过期**，导致所有的请求都直接访问数据库，从而导致数据库的流量激增，压力骤增，最终导致宕机。

## 缓存雪崩解决方案

- 随机过期时间
- 缓存永不过期
- 缓存预热
- 多级缓存

### 随机过期时间

该方案就是在给定一个固定的过期时间之后再随机加上一个随机数，从而避免大量缓存数据的同时过期。

示例代码如下：

```java
/**
 * Redis 优化分页查询
 *
 * @param queryRequest 查询参数
 * @return 分页结果
 */
@Override
public Page<PictureVO> listPictureVOByPageWithCache(PictureQueryRequest queryRequest) {
    // 1. 构建 Redis Key
    String jsonStr = JSONUtil.toJsonStr(queryRequest);
    String md5Str = DigestUtils.md5DigestAsHex(jsonStr.getBytes());
    final String key = "picture:listPictureVOByPage:" + md5Str;
    // 2. 先查询 Redis
    String valueData = redisTemplate.opsForValue().get(key);
    if (StrUtil.isNotBlank(valueData)) {
        // 缓存中存在数据, 直接返回(避免泛型擦除)
        return JSONUtil.toBean(valueData, new TypeReference<Page<PictureVO>>() {
        }, false);
    }
    // 3. 不存在, 查询数据库
    int current = queryRequest.getCurrent();
    int pageSize = queryRequest.getPageSize();
    Page<Picture> picturePage = this.page(new Page<>(current, pageSize), this.getQueryWrapper(queryRequest));
    Page<PictureVO> pictureVOPage = this.getPictureVOPage(picturePage);
    // 4. 写入数据到 Redis
    // 设置过期时间(添加随机时间, 防止缓存雪崩)
    int timeout = 300 + RandomUtil.randomInt(0, 300);
    redisTemplate.opsForValue().set(key, JSONUtil.toJsonStr(pictureVOPage), timeout, TimeUnit.SECONDS);
    return pictureVOPage;
}
```

### 缓存永不过期

该方案就是针对于几乎不会改变的数据不设置过期时间，在有需要修改的场景进行异步删除或更新即可。

### 缓存预热

利用定时任务提前对缓存做预热，保证用户直接查询缓存而不是数据库。

### 多级缓存

结合本地缓存与分布式缓存一起使用，并设置不同的过期时间，避免对数据库直接造成请求。比如本地缓存 Caffeine 结合分布式缓存 Redis 共同构成多级缓存，避免缓存雪崩。

下面是一个我之前项目中使用的一个多级缓存示例。
{% plantuml %}
' 设置整体样式
skinparam shadowing false

' 定义流程元素样式
skinparam activity {
BackgroundColor<<LocalCache>> #c4dcff
BackgroundColor<<RedisCache>> #c4dcff
BackgroundColor<<Database>> #c4dcff
BorderColor #343a40
StartColor #198754
StopColor #dc3545
ArrowColor #0d6efd
LineThickness 2
}

' 定义条件样式
skinparam if {
BackgroundColor #e9ecef
BorderColor #6c757d
RoundCorner 10
}

title 多级缓存活动图

start
:接收请求;
:查询本地缓存 Caffeine;
if (是否命中?) then (是)
:返回本地缓存数据;
stop
else (否)
:查询分布式缓存 Redis;
if (是否命中?) then (是)
:更新本地缓存;
:返回 Redis 缓存数据;
stop
else (否)
:查询数据库;
:更新本地缓存和 Redis 缓存;
:返回数据库数据;
stop
endif
endif
{% endplantuml %}

1、引入依赖 (JDK11+)

```xml
<!-- Caffeine -->
<dependency>
    <groupId>com.github.ben-manes.caffeine</groupId>
    <artifactId>caffeine</artifactId>
    <version>3.1.8</version>
</dependency>
```

2、Caffeine 缓存工具类

```java
/**
 * Caffeine 缓存工具类
 */
public class CaffeineUtil {
    private static final Cache<String, String> LOCAL_CACHE = Caffeine.newBuilder()
    .initialCapacity(1024) // 初始容量
    .maximumSize(10000L) // 最大容量
    .expireAfterWrite(5L, TimeUnit.MINUTES) // 5 分钟过期
    .build();

    public static Cache<String, String> getCache() {
        return LOCAL_CACHE;
    }
}
```

3、构建多级缓存示例：

```java
/**
 * Redis + Caffeine 多级缓存
 *
 * @param queryRequest 查询参数
 * @return 分页结果
 */
@Override
public Page<PictureVO> listPictureVOByPageWithCache(PictureQueryRequest queryRequest) {
    // 1. 构建 Key
    String jsonStr = JSONUtil.toJsonStr(queryRequest);
    String md5Str = DigestUtils.md5DigestAsHex(jsonStr.getBytes());
    final String key = "picture:listPictureVOByPage:" + md5Str;
    // 2. 先查询 Caffeine
    String valueData = CaffeineUtil.getCache().getIfPresent(key);
    if (StrUtil.isNotBlank(valueData)) {
        // 存在, 直接返回
        return JSONUtil.toBean(valueData, new TypeReference<Page<PictureVO>>() {
        }, false);
    }
    // 3. 不存在, 查询 Redis
    valueData = redisTemplate.opsForValue().get(key);
    if (StrUtil.isNotBlank(valueData)) {
        // redis 中存在, 先更新本地缓存, 再返回结果
        CaffeineUtil.getCache().put(key, valueData);
        return JSONUtil.toBean(valueData, new TypeReference<Page<PictureVO>>() {
        }, false);
    }
    // 4. 都不存在, 查询数据库
    int current = queryRequest.getCurrent();
    int pageSize = queryRequest.getPageSize();
    Page<Picture> picturePage = this.page(new Page<>(current, pageSize), this.getQueryWrapper(queryRequest));
    Page<PictureVO> pictureVOPage = this.getPictureVOPage(picturePage);
    // 5. 写入数据到 Caffeine
    CaffeineUtil.getCache().put(key, JSONUtil.toJsonStr(pictureVOPage));
    // 6. 写入数据到 Redis
    int timeout = 300 + RandomUtil.randomInt(0, 300);
    redisTemplate.opsForValue().set(key, JSONUtil.toJsonStr(pictureVOPage), timeout, TimeUnit.SECONDS);
    return pictureVOPage;
}
```

## 不可避免的缓存雪崩突发情况

针对于 Redis 突然宕机，或者内存不够导致淘汰其他缓存数据，或者机房被洪水淹了等不可抗力因素导致的缓存雪崩问题，我们有如下的对应方案：

1、做好 Redis 的高可用，要么搭建主从 + 哨兵节点要么搭建多主多从集群。

2、做好服务的降级限流熔断的服务保护措施，做好兜底。









































